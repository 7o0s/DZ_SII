{"ref": "https://www.eurogamer.net/r-prophet2mx", "date": "12 Sep 2000", "game_name": "Reviews", "text": "- GuillemotPrice - \u00a3130                    NVIDIA have been making great strides in the graphics chip market            with their incredibly fast GeForce and GeForce 2 chips recently,            but these are aimed at the top end of the market, which is not            where the majority of the money is to be made. As a result NVIDIA            have decided to make a move on the mainstream market with the            GeForce 2 MX chip.                        The hardware spec matches that of the low pricing of the board -            the main GPU itself runs at 175MHz (as opposed to the 200 on the            more expensive GeForce 2 GTS), and the memory is much cheaper and            slower SDR SDRAM running at 183MHz. But as the chip is essentially            based around the GeForce 2 it supports all the features of the            faster chip, such as AGP 4x support and fast writes, as well as            bringing the power of the 2nd generation hardware T&L engines            of the GTS to the mass market.                        It is interesting to see that NVIDIA have decided to return to SDR            memory after the great debacle that occurred with the original            launch of the GeForce 256, with respect to the bandwidth            limitations imposed by single cycle memory (SDR). The reasons for            this are obvious, as double data rate (DDR) memory is extremely            expensive in comparison to the more common SDR memory chips, which            are available from virtually every memory manufacturer on the            planet.                        In doing this the GeForce 2 MX's performance will be crippled in            comparison to the higher end cards, but we must remember that this            card is aimed at the mainstream, where price is the main issue and            good performance is something to hope for. Another benefit of the            slower memory is that the GPU itself becomes so terribly limited by            the lack of bandwidth between itself and the memory that it is no            longer necessary to have the chip running as fast. This means that            chips that would have failed to run at the 200MHz of the GTS can            now be used for the MX if they are capable of the 175MHz required,            thereby increasing yield and lowering costs.                    Today we are taking a look at one of the better MX boards on the            market - the Prophet 2 MX from Hercules. Guillemot recently            acquired the ailing American graphics card company Hercules in an            attempt to broaden their markets in the States, and it seems to            have paid off, except for the loss of the Guillemot brand here in            Europe.                        Apart from the name, one asset that Guillemot did pick up from            Hercules is their penchant for high quality board design. The            Prophet 2 MX is just as well designed as you would expect from            Hercules, and it is impressive how so much has been squeezed into            such a small space. The board itself is a rather snazzy blue, which            makes a very welcome change from the regular green PCBs we see in            most of our PCs. It is also incredibly small, measuring in at only            16cm long and 6.5cm high! This is certainly something that will sit            well with those users who are limited to cramped cases.                        This tiny card is adorned with a huge blue heatsink (no fan)            covering the equally large GeForce 2 MX GPU. A smattering of memory            adorns the back end of the card, which have no heatsinks (as seen            on the Prophet 2 GTS). The output takes the form of the usual 15pin            monitor connector - there are no other outputs from the card.                    The tests were all run on an Intel Pentium III 800e CPU, running on            a i440BX based motherboard with 256Mb PC100 SDRAM.                    From the Quake 3 performance we can see that, due to the slower SDR            memory, the card is having a little trouble keeping up with the            older GeForce DDR. This is a real sign of the memory bandwidth            limitations imposed by the SDR memory on the board. It would appear            that the maximum fill rate of 700Mtexels/sec isn't really being            used to the full, as this is some 220Mtexels/sec greater than the            GeForce DDR's maximum and yet the MX is still slower.                        The 3D Mark 2000 performance also highlights this massive memory            bottleneck problem. The GeForce 2 GTS is obviously way out in            front, but while the Prophet is edged out by the DDR GeForce the            margin is somewhat smaller, which does show that despite these            memory limitations the tweaked core of the MX is more powerful than            that of the original GeForce 256 chip.                    While the older GeForce DDR based boards may well be faster than            the Prophet 2 MX, they do still cost considerably more, and this is            where the MX will ultimately shine through. Priced at about            \u00a3130, the Prophet 2 MX is aimed squarely at the mainstream,            and as such it will doubtlessly be very successful.                        And while the performance isn't truly spectacular, one must            remember that this is the latest generation of NVIDIA's T&L            engine and texture pipelines, and as a result there will be            benefits from these refinements that aren't available in the            earlier GeForce 256 chips, which may well shine through as games            become more complex.                        The Prophet 2 MX is a great little card (literally) and if you are            in the market for something quick but don't have a depthless            wallet, then I would strongly urge you to consider the Prophet 2 MX            - you could do far worse.                        -        NVIDIA                    interviewNVIDIA                    interview                    Graphics Card Jargon Guide                    Graphics Card Jargon Guide"}